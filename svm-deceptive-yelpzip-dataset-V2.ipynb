{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "from sklearn.svm import OneClassSVM\n",
    "import pandas as pd\n",
    "import feather\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "np.random.seed(500)\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"df_yelpzip.pickle\",\"rb\")\n",
    "df = pickle.load(pickle_in)\n",
    "# df = pd.read_table(\"Data/YelpChi/output_review_yelpHotelData_NRYRcleaned.txt\",header=None)\n",
    "# df2 = pd.read_table(\"Data/YelpChi/output_meta_yelpHotelData_NRYRcleaned.txt\",header=None, sep=\" \")\n",
    "# df['label'] =  df2[4]\n",
    "# df['label'] = df['label'].replace(['N'],1)\n",
    "# df['label'] = df['label'].replace(['Y'],-1)\n",
    "# df.columns = ['review_content', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>review_content</th>\n",
       "      <th>word_count</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>text_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5044</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-11-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>drinks were bad, the hot chocolate was watered...</td>\n",
       "      <td>36</td>\n",
       "      <td>[drinks, were, bad, ,, the, hot, chocolate, wa...</td>\n",
       "      <td>['drink', 'bad', 'hot', 'chocolate', 'water', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5045</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-09-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>this was the worst experience i've ever had a ...</td>\n",
       "      <td>260</td>\n",
       "      <td>[this, was, the, worst, experience, i, 've, ev...</td>\n",
       "      <td>['bad', 'experience', 'ever', 'casual', 'fare'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5046</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-10-06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>this is located on the site of the old spruce ...</td>\n",
       "      <td>50</td>\n",
       "      <td>[this, is, located, on, the, site, of, the, ol...</td>\n",
       "      <td>['locate', 'site', 'old', 'spruce', 'video', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5046</td>\n",
       "      <td>376</td>\n",
       "      <td>2013-11-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>i am becoming frustrated with yelp.  i placed ...</td>\n",
       "      <td>62</td>\n",
       "      <td>[i, am, becoming, frustrated, with, yelp, ., i...</td>\n",
       "      <td>['become', 'frustrate', 'yelp', 'place', 'revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5047</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-11-30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>i enjoyed coffee and breakfast twice at toast ...</td>\n",
       "      <td>234</td>\n",
       "      <td>[i, enjoyed, coffee, and, breakfast, twice, at...</td>\n",
       "      <td>['enjoy', 'coffee', 'breakfast', 'twice', 'toa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304335</th>\n",
       "      <td>265232</td>\n",
       "      <td>5041</td>\n",
       "      <td>2014-12-13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>great local bar with a cozy atmosphere (firepl...</td>\n",
       "      <td>38</td>\n",
       "      <td>[great, local, bar, with, a, cozy, atmosphere,...</td>\n",
       "      <td>['great', 'local', 'bar', 'cozy', 'atmosphere'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304336</th>\n",
       "      <td>265233</td>\n",
       "      <td>5041</td>\n",
       "      <td>2014-12-11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>this cozy brooklyn restaurant is for sure a wi...</td>\n",
       "      <td>90</td>\n",
       "      <td>[this, cozy, brooklyn, restaurant, is, for, su...</td>\n",
       "      <td>['cozy', 'brooklyn', 'restaurant', 'sure', 'wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304337</th>\n",
       "      <td>265234</td>\n",
       "      <td>5041</td>\n",
       "      <td>2014-12-02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>i wanna let you in on one of brooklyn's best k...</td>\n",
       "      <td>229</td>\n",
       "      <td>[i, wan, na, let, you, in, on, one, of, brookl...</td>\n",
       "      <td>['wan', 'na', 'let', 'one', 'brooklyn', 'best'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304338</th>\n",
       "      <td>265235</td>\n",
       "      <td>5041</td>\n",
       "      <td>2014-10-30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>bijans is the best!!! i love it here. first le...</td>\n",
       "      <td>20735</td>\n",
       "      <td>[bijans, is, the, best, !, !, !, i, love, it, ...</td>\n",
       "      <td>['bijans', 'best', 'love', 'first', 'let', 'sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304339</th>\n",
       "      <td>265320</td>\n",
       "      <td>5039</td>\n",
       "      <td>2012-08-22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>stopped by this restaurant yesterday, we just ...</td>\n",
       "      <td>138</td>\n",
       "      <td>[stopped, by, this, restaurant, yesterday, ,, ...</td>\n",
       "      <td>['stop', 'restaurant', 'yesterday', 'want', 'q...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304340 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  prod_id        date  rating  label  \\\n",
       "0          5044        0  2014-11-16     1.0     -1   \n",
       "1          5045        0  2014-09-08     1.0     -1   \n",
       "2          5046        0  2013-10-06     3.0     -1   \n",
       "3          5046      376  2013-11-02     3.0     -1   \n",
       "4          5047        0  2014-11-30     5.0     -1   \n",
       "...         ...      ...         ...     ...    ...   \n",
       "304335   265232     5041  2014-12-13     5.0     -1   \n",
       "304336   265233     5041  2014-12-11     5.0     -1   \n",
       "304337   265234     5041  2014-12-02     5.0     -1   \n",
       "304338   265235     5041  2014-10-30     5.0     -1   \n",
       "304339   265320     5039  2012-08-22     1.0      1   \n",
       "\n",
       "                                           review_content  word_count  \\\n",
       "0       drinks were bad, the hot chocolate was watered...          36   \n",
       "1       this was the worst experience i've ever had a ...         260   \n",
       "2       this is located on the site of the old spruce ...          50   \n",
       "3       i am becoming frustrated with yelp.  i placed ...          62   \n",
       "4       i enjoyed coffee and breakfast twice at toast ...         234   \n",
       "...                                                   ...         ...   \n",
       "304335  great local bar with a cozy atmosphere (firepl...          38   \n",
       "304336  this cozy brooklyn restaurant is for sure a wi...          90   \n",
       "304337  i wanna let you in on one of brooklyn's best k...         229   \n",
       "304338  bijans is the best!!! i love it here. first le...       20735   \n",
       "304339  stopped by this restaurant yesterday, we just ...         138   \n",
       "\n",
       "                                                tokenized  \\\n",
       "0       [drinks, were, bad, ,, the, hot, chocolate, wa...   \n",
       "1       [this, was, the, worst, experience, i, 've, ev...   \n",
       "2       [this, is, located, on, the, site, of, the, ol...   \n",
       "3       [i, am, becoming, frustrated, with, yelp, ., i...   \n",
       "4       [i, enjoyed, coffee, and, breakfast, twice, at...   \n",
       "...                                                   ...   \n",
       "304335  [great, local, bar, with, a, cozy, atmosphere,...   \n",
       "304336  [this, cozy, brooklyn, restaurant, is, for, su...   \n",
       "304337  [i, wan, na, let, you, in, on, one, of, brookl...   \n",
       "304338  [bijans, is, the, best, !, !, !, i, love, it, ...   \n",
       "304339  [stopped, by, this, restaurant, yesterday, ,, ...   \n",
       "\n",
       "                                               text_final  \n",
       "0       ['drink', 'bad', 'hot', 'chocolate', 'water', ...  \n",
       "1       ['bad', 'experience', 'ever', 'casual', 'fare'...  \n",
       "2       ['locate', 'site', 'old', 'spruce', 'video', '...  \n",
       "3       ['become', 'frustrate', 'yelp', 'place', 'revi...  \n",
       "4       ['enjoy', 'coffee', 'breakfast', 'twice', 'toa...  \n",
       "...                                                   ...  \n",
       "304335  ['great', 'local', 'bar', 'cozy', 'atmosphere'...  \n",
       "304336  ['cozy', 'brooklyn', 'restaurant', 'sure', 'wi...  \n",
       "304337  ['wan', 'na', 'let', 'one', 'brooklyn', 'best'...  \n",
       "304338  ['bijans', 'best', 'love', 'first', 'let', 'sa...  \n",
       "304339  ['stop', 'restaurant', 'yesterday', 'want', 'q...  \n",
       "\n",
       "[304340 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative:  40832  positive: 263508 total 304340 percent deceptive 13.416573569034632\n"
     ]
    }
   ],
   "source": [
    "pos=0 \n",
    "neg = 0\n",
    "\n",
    "for x in df['label']:\n",
    "    if x == -1:\n",
    "        neg+=1\n",
    "    else:\n",
    "        pos+=1\n",
    "print ('negative: ', neg , ' positive:' , pos, 'total', neg+pos,'percent deceptive', neg*100.0/(neg+pos)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = '/home/parallels/KTH/II2202/Data/YelpNYC/database_feather.feather'\n",
    "#df = pd.read_feather(file_path, columns=None, use_threads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id             int32\n",
       "prod_id             int32\n",
       "date               object\n",
       "rating            float64\n",
       "label               int32\n",
       "review_content     object\n",
       "word_count          int32\n",
       "tokenized          object\n",
       "text_final         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>304340.000000</td>\n",
       "      <td>304340.000000</td>\n",
       "      <td>304340.000000</td>\n",
       "      <td>304340.000000</td>\n",
       "      <td>304340.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>90112.485523</td>\n",
       "      <td>2612.333233</td>\n",
       "      <td>3.924371</td>\n",
       "      <td>0.731669</td>\n",
       "      <td>240.906135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>74262.444989</td>\n",
       "      <td>1456.788655</td>\n",
       "      <td>1.145761</td>\n",
       "      <td>0.681662</td>\n",
       "      <td>2862.792327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5044.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25276.000000</td>\n",
       "      <td>1398.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>67841.500000</td>\n",
       "      <td>2711.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>143742.000000</td>\n",
       "      <td>3846.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>265320.000000</td>\n",
       "      <td>5043.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>267753.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id        prod_id         rating          label  \\\n",
       "count  304340.000000  304340.000000  304340.000000  304340.000000   \n",
       "mean    90112.485523    2612.333233       3.924371       0.731669   \n",
       "std     74262.444989    1456.788655       1.145761       0.681662   \n",
       "min      5044.000000       0.000000       1.000000      -1.000000   \n",
       "25%     25276.000000    1398.000000       3.000000       1.000000   \n",
       "50%     67841.500000    2711.000000       4.000000       1.000000   \n",
       "75%    143742.000000    3846.000000       5.000000       1.000000   \n",
       "max    265320.000000    5043.000000       5.000000       1.000000   \n",
       "\n",
       "          word_count  \n",
       "count  304340.000000  \n",
       "mean      240.906135  \n",
       "std      2862.792327  \n",
       "min         1.000000  \n",
       "25%        45.000000  \n",
       "50%        87.000000  \n",
       "75%       155.000000  \n",
       "max    267753.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step - a : Remove blank rows if any.\n",
    "# df['review_content'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step - b : Change all the text to lower case\n",
    "# df['review_content'] = [entry.lower() for entry in df['review_content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step - c : Tokenization : In this each entry in the corpus will be broken into set of words\n",
    "# # tokenized = []\n",
    "# # for index,entry in enumerate(genuine['review_content']): \n",
    "# #     genuine.loc[index,'tokenized'] = [word_tokenize(entry)]\n",
    "# #     percent = index/len(genuine)*100\n",
    "# #     print('percent done [%d%%]\\r'%percent, end=\"\")\n",
    "# df['tokenized']= [word_tokenize(entry) for entry in df['review_content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step - d : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
    "# # WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "# tag_map = defaultdict(lambda : wn.NOUN)\n",
    "# tag_map['J'] = wn.ADJ\n",
    "# tag_map['V'] = wn.VERB\n",
    "# tag_map['R'] = wn.ADV\n",
    "# final_text = [None]*len(df['tokenized'])\n",
    "# for index,entry in enumerate(df['tokenized']):\n",
    "#     # Declaring Empty List to store the words that follow the rules for this step\n",
    "#     Final_words = []\n",
    "#     # Initializing WordNetLemmatizer()\n",
    "#     percent = float(index/len(df['tokenized'])*100)\n",
    "\n",
    "#     print('percent done [%f%%]\\r'%percent, end=\"\")\n",
    "#     word_Lemmatized = WordNetLemmatizer()\n",
    "#     # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "#     for word, tag in pos_tag(entry):\n",
    "#         # Below condition is to check for Stop words and consider only alphabets\n",
    "#         if word not in stopwords.words('english') and word.isalpha():\n",
    "#             word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "#             Final_words.append(word_Final)\n",
    "#     # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "#     df.loc[index,'text_final'] = str(Final_words)\n",
    "#     final_text[index]=(Final_words)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to save the preporcessed list\n",
    "\n",
    "# pickle_out = open(\"df_lemma_yelp_chicago.pickle\",\"wb\")\n",
    "# pickle.dump(df, pickle_out)\n",
    "# pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304340, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df['text_final'].values.reshape(-1,1)\n",
    "y = df['label'].values.reshape(-1,1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "#oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X_under, y_under = undersample.fit_resample(x, y)\n",
    "#X_over, y_over = oversample.fit_resample(X, df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'text_final':X_under[:,0],'label':y_under[:,]}\n",
    "dfu = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_final</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['drink', 'bad', 'hot', 'chocolate', 'water', ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['bad', 'experience', 'ever', 'casual', 'fare'...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['locate', 'site', 'old', 'spruce', 'video', '...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['become', 'frustrate', 'yelp', 'place', 'revi...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['enjoy', 'coffee', 'breakfast', 'twice', 'toa...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81659</th>\n",
       "      <td>['randomly', 'find', 'mike', 'fusion', 'medite...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81660</th>\n",
       "      <td>['come', 'lunch', 'one', 'day', 'u', 'margarit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81661</th>\n",
       "      <td>['fly', 'lga', 'numerous', 'time', 'month', 'p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81662</th>\n",
       "      <td>['place', 'okay', 'sf', 'native', 'definitely'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81663</th>\n",
       "      <td>['prepare', 'wait', 'even', 'make', 'reservati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81664 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_final  label\n",
       "0      ['drink', 'bad', 'hot', 'chocolate', 'water', ...     -1\n",
       "1      ['bad', 'experience', 'ever', 'casual', 'fare'...     -1\n",
       "2      ['locate', 'site', 'old', 'spruce', 'video', '...     -1\n",
       "3      ['become', 'frustrate', 'yelp', 'place', 'revi...     -1\n",
       "4      ['enjoy', 'coffee', 'breakfast', 'twice', 'toa...     -1\n",
       "...                                                  ...    ...\n",
       "81659  ['randomly', 'find', 'mike', 'fusion', 'medite...      1\n",
       "81660  ['come', 'lunch', 'one', 'day', 'u', 'margarit...      1\n",
       "81661  ['fly', 'lga', 'numerous', 'time', 'month', 'p...      1\n",
       "81662  ['place', 'okay', 'sf', 'native', 'definitely'...      1\n",
       "81663  ['prepare', 'wait', 'even', 'make', 'reservati...      1\n",
       "\n",
       "[81664 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative:  40832  positive: 40832 total 81664 percent deceptive 50.0\n"
     ]
    }
   ],
   "source": [
    "pos=0 \n",
    "neg = 0\n",
    "for x in dfu['label']:\n",
    "    if x == -1:\n",
    "        neg+=1\n",
    "    else:\n",
    "        pos+=1\n",
    "print ('negative: ', neg , ' positive:' , pos, 'total', neg+pos,'percent deceptive', neg*100.0/(neg+pos)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X_oc_all, Test_X_oc_all = model_selection.train_test_split(dfu[['label','text_final']],test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative:  12246  positive: 12254 total 24500 percent deceptive 49.98367346938775\n"
     ]
    }
   ],
   "source": [
    "# check test genuine/deceptive\n",
    "pos=0 \n",
    "neg = 0\n",
    "\n",
    "for x in Test_X_oc_all['label']:\n",
    "    if x == -1:\n",
    "        neg+=1\n",
    "    else:\n",
    "        pos+=1\n",
    "print ('negative: ', neg , ' positive:' , pos, 'total', neg+pos,'percent deceptive', neg*100.0/(neg+pos)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split using genuine\n",
    "Train_X, Test_X = model_selection.train_test_split((Train_X_oc_all.loc[(dfu['label'] == 1)]).text_final,test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split using deceptive\n",
    "Train_X_dec, Test_X_dec = model_selection.train_test_split((Train_X_oc_all.loc[(dfu['label'] == -1)]).text_final,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=400)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=400)        \n",
    "Tfidf_vect.fit(df['text_final'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizing genuine data\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing deceptive data\n",
    "Train_X_Tfidf_dec = Tfidf_vect.transform(Train_X_dec)\n",
    "Test_X_Tfidf_dec = Tfidf_vect.transform(Test_X_oc_all['text_final'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing all data\n",
    "Test_X_Tfidf_all = Tfidf_vect.transform(df['text_final'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20004x400 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 597945 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X_Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time 154.43226647377014\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the classifier using [deceptive]\n",
    "start_time = time.time()\n",
    "\n",
    "clf_dec = OneClassSVM(gamma='auto', kernel='rbf', degree=5).fit(Train_X_Tfidf_dec)\n",
    "elapsed_time = time.time() - start_time\n",
    "print('elapsed_time' , elapsed_time)\n",
    "# predict the labels on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time 88.50089311599731\n"
     ]
    }
   ],
   "source": [
    "# predict using deceptive\n",
    "start_time = time.time()\n",
    "predictions_oneclass_dec = clf_dec.predict(Test_X_Tfidf_dec)\n",
    "#print(predictions_oneclass_dec)\n",
    "elapsed_time = time.time() - start_time\n",
    "print('elapsed_time' , elapsed_time)\n",
    "# Use accuracy_score function to get the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative:  11633  positive: 12867\n"
     ]
    }
   ],
   "source": [
    "# deceptive predict count\n",
    "pos=0 \n",
    "neg = 0\n",
    "\n",
    "for x in predictions_oneclass_dec:\n",
    "    if x == -1:\n",
    "        neg+=1\n",
    "    else:\n",
    "        pos+=1\n",
    "print ('negative: ', neg , ' positive:' , pos)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score ->  0.4731836734693878\n",
      "percision:  0.473123326369335  recall:  0.4731836734693878  fscore:  0.47284936214026957\n"
     ]
    }
   ],
   "source": [
    "cf_matrix=confusion_matrix(Test_X_oc_all['label'], predictions_oneclass_dec*-1)\n",
    "metrics_result = precision_recall_fscore_support(Test_X_oc_all['label'], predictions_oneclass_dec*-1, average='weighted',zero_division=0)\n",
    "print(\"Accuracy Score -> \",accuracy_score(predictions_oneclass_dec*-1, Test_X_oc_all['label'], normalize=True))\n",
    "print(\"percision: \", metrics_result[0], ' recall: ' , metrics_result[1], ' fscore: ', metrics_result[2])\n",
    "#print(metrics.f1_score(Test_X_oc_all['label'], predictions_oneclass_dec*-1, average='weighted'))\n",
    "#sns.heatmap(cf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time 90.1292736530304\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the classifier using [genuine]\n",
    "start_time = time.time()\n",
    "\n",
    "clf_gen = OneClassSVM(gamma='auto', kernel='poly', degree=5).fit(Train_X_Tfidf)\n",
    "elapsed_time = time.time() - start_time\n",
    "print('elapsed_time' , elapsed_time)\n",
    "# predict the labels on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using [genuine]\n",
    "start_time = time.time()\n",
    "predictions_oneclass_gen = clf_gen.predict(Test_X_Tfidf_dec)\n",
    "#print(predictions_oneclass_gen)\n",
    "elapsed_time = time.time() - start_time\n",
    "print('elapsed_time' , elapsed_time)\n",
    "# Use accuracy_score function to get the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of prediction using [genuine]\n",
    "pos=0 \n",
    "neg = 0\n",
    "\n",
    "for x in predictions_oneclass_gen:\n",
    "    if x == -1:\n",
    "        neg+=1\n",
    "    else:\n",
    "        pos+=1\n",
    "print ('negative: ', neg , ' positive:' , pos)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy Score -> \",accuracy_score(predictions_oneclass_gen, Test_X_oc_all['label'], normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to save the classifier model\n",
    "\n",
    "# pickle_out = open(\"clf_oneclass.pickle\",\"wb\")\n",
    "# pickle.dump(clf, pickle_out)\n",
    "# pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all, X_validation_all, Y_train_all, Y_validation_all = train_test_split(Tfidf_vect.transform(dfu['text_final']), dfu['label'], test_size=0.30, random_state=1,stratify=dfu['label'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfu['text_final']),len(Y_train_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=0 \n",
    "neg = 0\n",
    "for x in Y_train_all:\n",
    "    if x == -1:\n",
    "        neg+=1\n",
    "    else:\n",
    "        pos+=1\n",
    "print ('negative: ', neg , ' positive:' , pos, 'total', neg+pos,'percent deceptive', neg*100.0/(neg+pos)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier checker\n",
    "\n",
    "# your code\n",
    "models = []\n",
    "#models.append(['Logistic Regression', LogisticRegression(solver='liblinear', multi_class='ovr'),[],0,0])\n",
    "#models.append(['Linear Discriminant Analysis', LinearDiscriminantAnalysis(),[],0,0])\n",
    "#models.append(['K Nearest Neighbor', KNeighborsClassifier(),[],0,0])\n",
    "#models.append(['Decesion Tree Classifier', DecisionTreeClassifier(),[],0,0])\n",
    "#models.append(['Gaussien Naive Bayes', GaussianNB(),[],0,0])\n",
    "models.append(['Support Vector Machine', SVC(gamma='auto',kernel='rbf'),[],0,0])\n",
    "models.append(['Support Vector Machine', SVC(gamma='auto',kernel='poly'),[],0,0])\n",
    "models.append(['Support Vector Machine', SVC(gamma='auto',kernel='linear'),[],0,0])\n",
    "#models.append(['Random Forest', RandomForestClassifier(max_depth = 1000,random_state=1),[],0,0])\n",
    "\n",
    "models = np.array(models,dtype=object)\n",
    "\n",
    "for i in range(len(models)):\n",
    "    start_time = time.time()\n",
    "    #kfold = StratifiedKFold(n_splits=1, random_state=1, shuffle=True)\n",
    "    cv_results = cross_val_score(models[i,1], X_train_all, Y_train_all, scoring='accuracy')\n",
    "    models[i,2] = cv_results\n",
    "    models[i,3] = cv_results.mean()\n",
    "    models[i,4] = cv_results.std()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('%s: %f (%f) elapsed time: %f' % (models[i,0], models[i,3], models[i,4],elapsed_time))\n",
    "    \n",
    "    \n",
    "\n",
    "best_model= models[np.argmax(models[:,3]),:]\n",
    "print(\"the best model performer is: \", best_model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model=SVC(gamma='auto',kernel='linear',degree=2).fit(X_train_all, Y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=clf_model.predict(X_validation_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=0 \n",
    "neg = 0\n",
    "for x in result:\n",
    "    if x == -1:\n",
    "        neg+=1\n",
    "    else:\n",
    "        pos+=1\n",
    "print ('negative: ', neg , ' positive:' , pos, 'total', neg+pos,'percent deceptive', neg*100.0/(neg+pos)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy Score -> \",accuracy_score(result, Y_validation_all, normalize=True))\n",
    "metrics_result = precision_recall_fscore_support(Y_validation_all, result, average='binary',zero_division=0)\n",
    "print(\"percision: \", metrics_result[0], ' recall: ' , metrics_result[1], ' fscore: ', metrics_result[2], '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= df[['text_final','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3= pd.concat([df2, dfu]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=0 \n",
    "neg = 0\n",
    "for x in df3['label']:\n",
    "    if x == -1:\n",
    "        neg+=1\n",
    "    else:\n",
    "        pos+=1\n",
    "print ('negative: ', neg , ' positive:' , pos, 'total', neg+pos,'percent deceptive', neg*100.0/(neg+pos)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split using genuine\n",
    "perc=(1- len(Y_train_all)/len(df3))\n",
    "Train_X_oneclass, Test_X_oneclass = model_selection.train_test_split((df3.loc[(df['label'] == 1)]).text_final,test_size=perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X_oneclass.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_features = 100;\n",
    "# while max_features < 5000:\n",
    "#     Tfidf_vect = TfidfVectorizer(max_features=max_features)        \n",
    "#     Tfidf_vect.fit(df['text_final'])\n",
    "#     Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "#     Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n",
    "#     Train_X_Tfidf_dec = Tfidf_vect.transform(Train_X_dec)\n",
    "#     Test_X_Tfidf_dec = Tfidf_vect.transform(Test_X_oc_all['text_final'])\n",
    "#     one_class_train = Tfidf_vect.transform(Train_X_oneclass)\n",
    "    \n",
    "#     clf_result = OneClassSVM( kernel='poly', degree=2).fit(one_class_train)\n",
    "#     predict_result = clf_result.predict(Test_X_Tfidf_dec)\n",
    "#     acc = accuracy_score(predict_result*1, Test_X_oc_all['label'], normalize=True)\n",
    "#     metrics_result = precision_recall_fscore_support(Test_X_oc_all['label'], predict_result*1, average='weighted',zero_division=0)\n",
    "#     print('features used: ', max_features, ' accuracy: ', acc)\n",
    "#     print(\"percision: \", metrics_result[0], ' recall: ' , metrics_result[1], ' fscore: ', metrics_result[2], '\\n')  \n",
    "    \n",
    "#     max_features += 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_class_train = Tfidf_vect.transform(Train_X_oneclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_class_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the training dataset on the classifier\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "degrees = [0,1,2,3]\n",
    "classifiers = []\n",
    "for kern in kernels:\n",
    "    start_time = time.time()\n",
    "    if kern == 'poly':\n",
    "        for deg in degrees:\n",
    "            start_time = time.time()\n",
    "            clf_result = OneClassSVM( kernel=kern, degree=deg).fit(one_class_train)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            classifiers.append([kern,deg,clf_result,elapsed_time])\n",
    "            print('kernel used: ' , kern, ' degree used: ' , deg, ' elapsed_time:' , elapsed_time)\n",
    "            \n",
    "    else:\n",
    "        clf_result = OneClassSVM(gamma='auto', kernel=kern).fit(Train_X_Tfidf_dec)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        classifiers.append([kern,0,clf_result,elapsed_time])\n",
    "        print('kernel used: ' , kern, ' elapsed_time: ' , elapsed_time)\n",
    "\n",
    "# predict the labels on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_result = []\n",
    "for clas in classifiers:\n",
    "    start_time = time.time()\n",
    "    predict_result = clas[2].predict(Test_X_Tfidf_dec)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    clas_result.append([clas[0],clas[1],clas[2],predict_result])\n",
    "    acc = accuracy_score(predict_result*1, Test_X_oc_all['label'], normalize=True)\n",
    "    metrics_result = precision_recall_fscore_support(Test_X_oc_all['label'], predict_result*1, average='binary',zero_division=0)\n",
    "    print('kernel used: ' , clas[0], ' degree used:' , clas[1], ' elapsed_time: ' , elapsed_time, ' accuracy: ', acc)\n",
    "    print(\"percision: \", metrics_result[0], ' recall: ' , metrics_result[1], ' fscore: ', metrics_result[2], '\\n')  \n",
    "# predict the labels on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_result = OneClassSVM( kernel='poly', degree=2).fit(one_class_train)\n",
    "predict_result = clf_result.predict(Test_X_Tfidf_dec)\n",
    "\n",
    "cf_matrix=confusion_matrix(Test_X_oc_all['label'], predict_result*1)\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
